gpu_mem_incr: True  # allocate GPU memory incrementally; use True at AOPP (and False at ECMWF?)
use_gpu: True  # use GPU _if possible_ (False guarantees that it will not be used).  this is done by setting or unsetting the CUDA_VISIBLE_DEVICES environment variable
disable_tf32: False  # whether to explicitly disable the use of TensorFloat-32 calculations when running on the GPU
mode: "GAN" # choices 'det' 'GAN' 'VAEGAN'
problem_type: "normal" # choices 'normal' 'superresolution'
downsample: False
architecture: "forceconv" # choices 'normal' 'forceconv'
padding: "reflect"  # convolution padding: 'same', 'reflect', or 'symmetric'
log_folder: "/user/work/uz22147/logs/cgan"
downscaling_factor: 3  # increase in image size in each dimension
downscaling_steps: [3]  # list of integers that multiply to the downscaling factor; the generator will use UpSampling2D layers of these sizes, alternating with residual blocks.

generator:
    filters_gen: 64
    noise_channels: 4 # used for GAN
    latent_variables: 1 # used for VAEGAN
    learning_rate_gen: 1e-5

discriminator:
    filters_disc: 256
    learning_rate_disc: 1e-5

train:
    training_range: ['200301', '201912'] # Start and end of training period, in YYYYMM format
    training_weights: [0.25, 0.25, 0.25, 0.25]
    num_epochs: 5
    steps_per_checkpoint: 4200
    batch_size: 2  # can use 400x16 without CL, or 3200x2 with CL
    kl_weight: 1e-8  # used for VAEGAN
    ensemble_size: 8  # size of pred ensemble for content loss
    CL_type: "ensmeanMSE" # type of content loss to use: 'CRPS', 'CRPS_phys', 'ensmeanMSE', 'ensmeanMSE_phys'
    content_loss_weight: 1000.0
    img_chunk_width: 40
    #create_TFRecords: False

val:
    val_range: ['202001', '202012'] # cannot pass a list if using create_fixed_dataset
    val_size: 100
    ensemble_size: 20
    #create_TFRecords: True


